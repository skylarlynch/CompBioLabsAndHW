#Sorting Herbarium Data
##Biological question
Phenology is the study of the changes in the timing of life events, such as flowering or fruiting in plants. Phenological shifts help reveal the effects of climate change and predict how these changes will affect the ecosystems in the future (Menzel, 2002). Herbarium specimens make the study of plant phenology possible, given the global herbarium record dates back centuries and encompasses a wealth of knowledge. I am conducting a meta-analysis that explores shifts in flowering periods of angiosperms deriving from both wet and dry habitats of every major landmass at tropical latitudes. Both wet and dry habitats are threatened by climate change, however dry climates are oftentimes at greater risk despite the emphasis being on wet habitats by most media outlets and conservation initiatives. I specifically predict that because of their sensitivities to changes in precipitation, dry forests will experience  more drastic changes in timing of flowering events.
##Context (introduction)
Representative study sites have been delimited on every major landmass, in a pairwise format. Locations were chosen based on their likelihood of having an abundance of herbarium specimens from diverse lineages and herbarium specimens that span long enough time periods, as well as a history of minimal human disturbance; as such, the majority of selected sites derive from field research stations. Digitized specimen records are being collected from online databases, primarily GBIF, and supplemented by numerous others such as iDiGBiO, Symbiota, and NYBG’s Starr Herbarium.
##Methods
#####The source of the data:
Development of my minimum criteria (for inclusion of a species or set of species into my study) was guided by reviewing existing literature on using herbarium specimens to understand the effects of climate change (Jones et al., 2018). These criteria require that each prospective study site hosts a minimum of thirty species, each with a minimum of thirty specimens per species, and these collected over a minimum of a fifty year time span. As of now, data have been collected from online databases including large aggregator databases (e.g., GBIF, iDigBio). Herbarium data is standardized into Darwin Core format.

The data always includes the following information: occurrenceID, institutionCode, basisOfRecord, catalogNumber, recordedBy, recordNumber, Year, month, day, Continent, country, stateProvince, county, locality, minimumElevationInMeters, maximumElevationInMeters, decimalLatitude, decimalLongitude, georeferenceProtocol, coordinateUncertaintyInMeters, Kingdom, phylum, class, family, order, genus, specificEpithet, infraspecificEpithet, scientificName, identificationQualifier, identifiedBy, yearIdentified, monthIdentified, dayIdentified, typeStatus, Dcterms:references, associatedMedia.
Not every database or herbarium has everything in the same order, some have more subsections than listed above.Some have varying formats. Right now, I just need to do step 1. I have 405,000 rows of data or 22,275,000 data points (and that number is soon to grow). By reviewing the literature, I have determined for a species to be statistically useful to me it needs to have at least 30 specimens, collected over at least 50 years. Even that I have narrowed down due to the time constraint. I have narrowed this project down to just finding the species that have at least 30 specimens. 
I have decided, due to the difference in format between the data that is from varying databases, not to use the join function. Because the headers are not all the same and not in the same order, It would be difficult and messy. I also only needed the scientific name, year, month, and specimen number, so I decided to take those columns out and combine them by hand in an excel document, and download that as a CSV document. 
When inputting the data, I decided to write the code to select a document from my computer, instead of inputting a single document by name. This allowed me to input all of the individual documents using the same piece of code.
In the way I wrote the code, I decided to make each of the numbers I would need to add, an individual argument, so that if I am ever able to polish it enough to share with the world, it will be user friendly. Just change the values of the arguments to whatever you would have as your criterium. As of now I only have one, but as I add to this code I will keep this format going forward. 
Next, I decided to use dplyr, because it would make things much more simple. I used the group by function to group everything by the headers I had assigned, which were ScientificName, year and ID. I then used tally to count them. This was all in a pipeline. 
In a new line I used the filter_if function, and made it greater than or equal to the above mentioned threshold. 
##Results and conclusions
The code is still slightly glitchy. It doesn’t always recognize the column names, and says it’s ‘not found’, but other times it’s worked. I am not sure why that is. I am also not sure yet if it would be easier for my research as a whole to have it return only the scientific names of the species that match my criteria, in a list, or if it should return the entire dataframe, removing the ones that don’t match. 
I would have also liked to have gotten a chance to play around with finch, the package that is specifically for working with data that is in darwin core format. That may have made things easier, but it just wasn’t in my time limit to learn an entirely new package. 
Lastly, I spoke with my committee earlier this week and realized I may need to completely change my parameters, not just picking a different value, but reworking it all together, and for that reason, I put a little less time into making sure this code was perfect, as I may not be able to use it in the end anyway. It was good practise and problem solving nonetheless. Thank you for everything Sam, you have been great and really helped me get over my fear of R and working with data. I will see you around and will likely be asking you more questions in the future. :)

